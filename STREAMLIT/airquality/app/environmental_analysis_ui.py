#!/usr/bin/env python3
"""
Module UI pour l'analyse environnementale (YOLO + Cartes)
Int√®gre la d√©tection d'objets et l'analyse de segmentation
"""

import streamlit as st
import os
import sys
import logging
from pathlib import Path
import json
from PIL import Image
import pandas as pd
from datetime import datetime
import re

# Augmenter limite PIL pour √©viter l'erreur "decompression bomb"
Image.MAX_IMAGE_PIXELS = 500000000  # 500 millions de pixels

logger = logging.getLogger(__name__)

# Chemins vers les modules existants
TRAIN_YOLO_PATH = Path(__file__).parent.parent.parent.parent / "train-yolo"
IMAGE_ANALYSIS_PATH = Path(__file__).parent.parent.parent / "Image-Analysis"
MAP_ANALYSIS_PATH = IMAGE_ANALYSIS_PATH / "map-anlaysis"

# Ajouter aux paths si n√©cessaire
if str(TRAIN_YOLO_PATH) not in sys.path:
    sys.path.insert(0, str(TRAIN_YOLO_PATH))
if str(MAP_ANALYSIS_PATH) not in sys.path:
    sys.path.insert(0, str(MAP_ANALYSIS_PATH))


def check_gpu_availability():
    """V√©rifie la disponibilit√© du GPU (M1 via MPS)"""
    try:
        import torch
        if torch.backends.mps.is_available():
            return 'mps', '‚úÖ GPU M1 (MPS) disponible'
        elif torch.cuda.is_available():
            return 'cuda', '‚úÖ GPU CUDA disponible'
        else:
            return 'cpu', '‚ö†Ô∏è CPU uniquement'
    except Exception as e:
        logger.warning(f"Erreur d√©tection GPU: {e}")
        return 'cpu', '‚ö†Ô∏è CPU uniquement'


@st.cache_data(ttl=300)  # Cache 5 minutes
def get_available_models():
    """Liste les mod√®les YOLO disponibles"""
    models = {}
    
    # Mod√®le pr√©-entra√Æn√© YOLO11n (d√©tection g√©n√©rale)
    yolo11n_path = Path(__file__).parent.parent.parent.parent / "ultralytics-main" / "yolo11n.pt"
    if yolo11n_path.exists():
        models['yolo11n'] = {
            'path': str(yolo11n_path),
            'name': 'YOLO11n (g√©n√©ral)',
            'type': 'pretrained',
            'description': 'D√©tection g√©n√©rale : voitures, personnes, v√©los, etc.'
        }
    
    # Mod√®le sp√©cialis√© arbres (tree detection)
    # Le mod√®le Trained_model.pt est le mod√®le sp√©cialis√© pour d√©tecter les arbres
    tree_model_paths = [
        IMAGE_ANALYSIS_PATH / "trained-yolo-model" / "Trained_model.pt",
        Path(__file__).parent.parent.parent.parent / "STREAMLIT" / "Image-Analysis" / "trained-yolo-model" / "Trained_model.pt",
        TRAIN_YOLO_PATH / "results" / "train" / "weights" / "best.pt"
    ]
    
    for tree_model_path in tree_model_paths:
        if tree_model_path.exists():
            models['tree_model'] = {
                'path': str(tree_model_path),
                'name': 'Tree Model (arbres)',
                'type': 'tree_specialist',
                'description': 'Sp√©cialis√© d√©tection arbres et v√©g√©tation'
            }
            break
    
    # Option combin√©e (YOLO11n + Tree Model)
    if 'yolo11n' in models and 'tree_model' in models:
        models['combined'] = {
            'path': [models['yolo11n']['path'], models['tree_model']['path']],
            'name': 'Combin√© (g√©n√©ral + arbres)',
            'type': 'combined',
            'description': 'Combine d√©tection g√©n√©rale YOLO11n et arbres sp√©cialis√©s'
        }
    
    return models


@st.cache_data(ttl=300)  # Cache 5 minutes
def get_satellite_images(address: str):
    """R√©cup√®re les images satellites t√©l√©charg√©es pour une adresse"""
    # Normaliser l'adresse
    try:
        from db_async_wrapper import DatabaseManager
        normalized = DatabaseManager.sanitize_address(address)
    except ImportError:
        # Fallback si db_utils non disponible
        normalized = re.sub(r'[^\w\s-]', '', address.lower())
        normalized = re.sub(r'[\s_-]+', '_', normalized).strip('_')
    
    sat_dir = Path(__file__).parent / "environment_data" / "satellite" / normalized
    
    if not sat_dir.exists():
        logger.warning(f"Dossier satellite introuvable: {sat_dir}")
        return []
    
    images = []
    for img_file in sat_dir.glob("*.png"):
        if img_file.name != "metadata.json":
            images.append({
                'path': str(img_file),
                'name': img_file.name
            })
    
    logger.info(f"‚úÖ {len(images)} images satellites trouv√©es dans {sat_dir}")
    return images


@st.cache_data(ttl=300)  # Cache 5 minutes
def get_streetview_images(address: str):
    """R√©cup√®re les images Street View t√©l√©charg√©es pour une adresse"""
    # Normaliser l'adresse
    try:
        from db_async_wrapper import DatabaseManager
        normalized = DatabaseManager.sanitize_address(address)
    except ImportError:
        # Fallback si db_utils non disponible
        normalized = re.sub(r'[^\w\s-]', '', address.lower())
        normalized = re.sub(r'[\s_-]+', '_', normalized).strip('_')
    
    sv_dir = Path(__file__).parent / "environment_data" / "streetview" / normalized
    
    if not sv_dir.exists():
        logger.warning(f"Dossier Street View introuvable: {sv_dir}")
        return []
    
    images = []
    for img_file in sv_dir.glob("*.jpg"):
        images.append({
            'path': str(img_file),
            'name': img_file.name
        })
    
    logger.info(f"‚úÖ {len(images)} images Street View trouv√©es dans {sv_dir}")
    return images


def _get_normalized_address(address: str) -> str:
    """Normalise une adresse pour l'utiliser comme nom de dossier."""
    try:
        from db_async_wrapper import DatabaseManager
        return DatabaseManager.sanitize_address(address)
    except ImportError:
        normalized = re.sub(r'[^\w\s-]', '', address.lower())
        return re.sub(r'[\s_-]+', '_', normalized).strip('_')


def run_yolo_detection(model_path, images: list, device: str = 'mps', conf: float = 0.25, is_combined: bool = False, address: str = None):
    """
    Lance la d√©tection YOLO sur les images

    Args:
        model_path: Chemin vers le mod√®le YOLO (str) ou liste de chemins (combined)
        images: Liste des chemins d'images
        device: Device √† utiliser ('mps', 'cuda', 'cpu')
        conf: Seuil de confiance
        is_combined: True si mode combin√© (2 mod√®les)
        address: Adresse pour organiser les r√©sultats par dossier

    Returns:
        R√©sultats de d√©tection
    """
    try:
        # Import YOLO
        from ultralytics import YOLO

        # Import du gestionnaire de r√©sultats
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "detection_resultats",
            TRAIN_YOLO_PATH / "detection-resultats.py"
        )
        detection_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(detection_module)
        DetectionResultsManager = detection_module.DetectionResultsManager

        # Cr√©er dossier de sortie par adresse
        base_output_dir = Path(__file__).parent / "environment_data" / "yolo_results"
        if address:
            normalized = _get_normalized_address(address)
            output_dir = base_output_dir / normalized
        else:
            output_dir = base_output_dir
        output_dir.mkdir(parents=True, exist_ok=True)

        if is_combined and isinstance(model_path, list):
            # MODE COMBIN√â : 2 mod√®les
            logger.info("üîç Mode combin√© : 2 mod√®les")

            all_results = []
            all_class_names = {}

            for idx, path in enumerate(model_path):
                model_name = "g√©n√©ral" if idx == 0 else "arbres"
                logger.info(f"üîç Chargement mod√®le {idx+1}/2 ({model_name}): {path}")
                model = YOLO(path)

                # Fusionner les noms de classes
                if hasattr(model, 'names'):
                    all_class_names.update(model.names)

                logger.info(f"üöÄ D√©tection avec mod√®le {model_name} sur {len(images)} images (device={device})")

                # Lancer pr√©dictions
                results = model.predict(
                    source=images,
                    save=True,
                    device=device,
                    conf=conf,
                    project=str(output_dir),
                    name=f'detection_{model_name}',
                    exist_ok=True
                )

                all_results.extend(results)

            logger.info(f"‚úÖ D√©tection combin√©e termin√©e : {len(all_results)} r√©sultats")

            # Traiter tous les r√©sultats combin√©s
            results_manager = DetectionResultsManager(class_names=all_class_names)
            results_data = results_manager.process_results(all_results)

            return results_data, str(output_dir / "detection_g√©n√©ral")

        else:
            # MODE SIMPLE : 1 mod√®le
            logger.info(f"üîç Chargement du mod√®le: {model_path}")
            model = YOLO(model_path)

            # R√©cup√©rer les noms de classes
            class_names = model.names if hasattr(model, 'names') else {}

            logger.info(f"üöÄ Lancement d√©tection sur {len(images)} images (device={device})")

            # Lancer les pr√©dictions
            results = model.predict(
                source=images,
                save=True,
                device=device,
                conf=conf,
                project=str(output_dir),
                name='detection',
                exist_ok=True
            )

            # Traiter les r√©sultats
            results_manager = DetectionResultsManager(class_names=class_names)
            results_data = results_manager.process_results(results)

            logger.info(f"‚úÖ D√©tection termin√©e: {results_data['metadata']['total_detections']} d√©tections")

            return results_data, str(output_dir / "detection")

    except Exception as e:
        logger.error(f"‚ùå Erreur YOLO: {e}")
        raise


def run_map_analysis(satellite_path: str, roadmap_path: str, zoom: int = 17, address: str = None):
    """
    Lance l'analyse de cartes

    Args:
        satellite_path: Chemin image satellite
        roadmap_path: Chemin image roadmap
        zoom: Niveau de zoom
        address: Adresse pour organiser les r√©sultats par dossier

    Returns:
        R√©sultats d'analyse
    """
    try:
        from map_analyzer import EnhancedMapAnalyzer

        logger.info(f"üó∫Ô∏è Analyse de cartes (zoom {zoom})")

        # Cr√©er l'analyseur
        analyzer = EnhancedMapAnalyzer(zoom_level=zoom, pixel_to_meter=0.6)

        # Charger les images
        analyzer.load_images(satellite_path, roadmap_path)

        # Analyser
        results = analyzer.analyze_full()

        # Cr√©er dossier de sortie par adresse
        base_output_dir = Path(__file__).parent / "environment_data" / "map_analysis"
        if address:
            normalized = _get_normalized_address(address)
            output_dir = base_output_dir / normalized
        else:
            output_dir = base_output_dir
        output_dir.mkdir(parents=True, exist_ok=True)

        # Sauvegarder
        analyzer.save_results(str(output_dir))

        logger.info(f"‚úÖ Analyse termin√©e, r√©sultats dans {output_dir}")

        return results, str(output_dir)

    except Exception as e:
        logger.error(f"‚ùå Erreur analyse cartes: {e}")
        raise


def display_yolo_results(results_data: dict, output_dir: str):
    """Affiche les r√©sultats YOLO"""
    st.subheader("üìä R√©sum√© des d√©tections")
    
    # M√©triques principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üñºÔ∏è Images analys√©es", results_data['metadata']['total_images'])
    
    with col2:
        st.metric("üéØ D√©tections totales", results_data['metadata']['total_detections'])
    
    with col3:
        unique_classes = len(results_data['summary'])
        st.metric("üè∑Ô∏è Classes d√©tect√©es", unique_classes)
    
    with col4:
        avg_per_image = results_data['metadata']['total_detections'] / max(results_data['metadata']['total_images'], 1)
        st.metric("üìà Moyenne / image", f"{avg_per_image:.1f}")
    
    st.divider()
    
    # R√©sum√© par classe avec cartes
    st.subheader("üìã D√©tections par classe")
    
    if results_data['summary']:
        # Afficher les statistiques principales en cartes
        summary_items = list(results_data['summary'].items())
        num_classes = len(summary_items)
        
        if num_classes > 0:
            # Afficher jusqu'√† 4 classes principales en cartes
            cols = st.columns(min(4, num_classes))
            for idx, (class_name, stats) in enumerate(summary_items[:4]):
                with cols[idx]:
                    st.metric(
                        label=f"üè∑Ô∏è {class_name}",
                        value=stats.get('total_count', 0),
                        delta=f"{stats.get('average_per_image', 0):.1f} / image"
                    )
        
        # Tableau d√©taill√©
        st.divider()
        st.write("**üìä Tableau d√©taill√©**")
        
        summary_data = []
        for class_name, stats in results_data['summary'].items():
            summary_data.append({
                'Classe': class_name,
                'Nombre total': stats.get('total_count', 0),
                'Moyenne par image': f"{stats.get('average_per_image', 0):.1f}",
                'Surface moy. (px¬≤)': f"{stats.get('average_surface_pixels', 0):.0f}",
                'Surface totale (px¬≤)': f"{stats.get('total_surface_pixels', 0):.0f}"
            })
        
        df_summary = pd.DataFrame(summary_data)
        st.dataframe(df_summary, hide_index=True)
    else:
        st.info("Aucune d√©tection trouv√©e")
    
    # Images annot√©es
    st.divider()
    st.subheader("üñºÔ∏è Images annot√©es")
    
    # Chercher les images dans tous les sous-dossiers
    output_path = Path(output_dir)
    result_imgs = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        result_imgs.extend(output_path.rglob(ext))
    
    if result_imgs:
        st.write(f"üì∏ {len(result_imgs)} images avec d√©tections")
        cols = st.columns(3)
        for idx, img_path in enumerate(result_imgs[:12]):  # Max 12 images
            with cols[idx % 3]:
                try:
                    with Image.open(img_path) as img:
                        st.image(img, caption=img_path.name)
                except Exception as e:
                    logger.warning(f"Impossible d'afficher {img_path}: {e}")
    else:
        st.warning(f"‚ö†Ô∏è Aucune image annot√©e trouv√©e dans {output_dir}")
        st.info(f"üìÅ V√©rifiez le dossier : `{output_dir}`")


def display_map_analysis_results(results: dict, output_dir: str):
    """Affiche les r√©sultats d'analyse de cartes"""
    st.subheader("üó∫Ô∏è Segmentation de la carte")
    
    # M√©triques de couverture
    st.write("**üìä Couverture du sol**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    # Support du format statistics_z*.json (nested sous 'elements')
    data_source = results.get('elements', results)
    
    with col1:
        # Compatible avec 'vegetation' (ancien) et 'green_spaces' (nouveau)
        veg_data = data_source.get('green_spaces', data_source.get('vegetation', {}))
        # Support pour format metrics direct ou nested
        if 'metrics' in veg_data:
             coverage = veg_data['metrics'].get('coverage_percent', 0)
        else:
             coverage = veg_data.get('coverage_percent', 0)
        st.metric("üå≥ V√©g√©tation", f"{coverage:.1f}%")
    
    with col2:
        roads_data = data_source.get('roads', {})
        if 'metrics' in roads_data:
             coverage = roads_data['metrics'].get('coverage_percent', 0)
        else:
             coverage = roads_data.get('coverage_percent', 0)
        st.metric("üõ£Ô∏è Routes", f"{coverage:.1f}%")
    
    with col3:
        build_data = data_source.get('buildings', {})
        if 'metrics' in build_data:
             coverage = build_data['metrics'].get('coverage_percent', 0)
        else:
             coverage = build_data.get('coverage_percent', 0)
        st.metric("üè¢ B√¢timents", f"{coverage:.1f}%")
    
    with col4:
        water_data = data_source.get('water', {})
        if 'metrics' in water_data:
             coverage = water_data['metrics'].get('coverage_percent', 0)
        else:
             coverage = water_data.get('coverage_percent', 0)
        st.metric("üíß Eau", f"{coverage:.1f}%")
    
    st.divider()
    
    # Images de segmentation
    st.subheader("üé® Visualisation")
    
    output_path = Path(output_dir)
    
    # Chercher les images g√©n√©r√©es
    segmentation_img = list(output_path.glob("segmentation_*.png"))
    overlay_img = list(output_path.glob("overlay_*.png"))
    
    col_left, col_right = st.columns(2)
    
    with col_left:
        if segmentation_img:
            st.write("**Segmentation color√©e**")
            with Image.open(segmentation_img[0]) as img:
                st.image(img)
    
    with col_right:
        if overlay_img:
            st.write("**Superposition**")
            with Image.open(overlay_img[0]) as img:
                st.image(img)
    
    # L√©gende
    st.info("""
    üå≥ **Vert** : V√©g√©tation | üõ£Ô∏è **Gris** : Routes | üè¢ **Rouge** : B√¢timents | üíß **Bleu** : Eau
    """)


def display_environmental_analysis(address: str):
    """
    Section principale d'analyse environnementale
    
    Args:
        address: Adresse analys√©e
    """
    st.header("üî¨ Analyse Environnementale")
    
    st.info("""
    Cette section combine la d√©tection d'objets (YOLO) et l'analyse de segmentation des cartes 
    pour fournir une analyse compl√®te de l'environnement.
    """)
    
    # V√©rifier disponibilit√© GPU
    device, gpu_status = check_gpu_availability()
    st.caption(gpu_status)
    
    st.divider()
    
    # === SECTION 1: D√âTECTION D'OBJETS (YOLO) ===
    st.subheader("üéØ D√©tection d'objets (YOLO)")
    
    # R√©cup√©rer les images disponibles
    streetview_images = get_streetview_images(address)
    
    if not streetview_images:
        st.warning("‚ö†Ô∏è Aucune image Street View disponible. T√©l√©chargez d'abord les images dans l'onglet 'üó∫Ô∏è Cartes & Images'.")
    else:
        st.success(f"‚úÖ {len(streetview_images)} images Street View disponibles")
        
        # S√©lection du mod√®le
        available_models = get_available_models()
        
        if not available_models:
            st.error("‚ùå Aucun mod√®le YOLO trouv√©. V√©rifiez les chemins des mod√®les.")
        else:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                model_options = {k: v['name'] for k, v in available_models.items()}
                selected_model = st.selectbox(
                    "Choisir un mod√®le",
                    options=list(model_options.keys()),
                    format_func=lambda x: model_options[x],
                    help="S√©lectionnez le mod√®le YOLO √† utiliser pour la d√©tection"
                )
            
            with col2:
                conf_threshold = st.slider("Seuil de confiance", 0.1, 0.9, 0.25, 0.05)
            
            # Afficher la description du mod√®le s√©lectionn√©
            model_info = available_models[selected_model]
            st.info(f"‚ÑπÔ∏è **{model_info['name']}** : {model_info['description']}")
            
            # Bouton de lancement
            if st.button("üöÄ Lancer la d√©tection YOLO", type="primary"):
                model_path = available_models[selected_model]['path']
                image_paths = [img['path'] for img in streetview_images]
                
                # D√©tecter si c'est le mode combin√©
                is_combined = selected_model == 'combined'
                
                with st.spinner(f"üîç Analyse en cours avec {model_options[selected_model]}..."):
                    try:
                        results_data, output_dir = run_yolo_detection(
                            model_path=model_path,
                            images=image_paths,
                            device=device,
                            conf=conf_threshold,
                            is_combined=is_combined,
                            address=address
                        )
                        
                        # Sauvegarder sur disque au lieu de session_state (√©conomie m√©moire)
                        results_file = Path(output_dir) / "yolo_results.json"
                        with open(results_file, 'w', encoding='utf-8') as f:
                            json.dump(results_data, f, ensure_ascii=False, indent=2)
                        
                        # ‚úÖ Sauvegarder aussi en PostgreSQL
                        try:
                            import asyncio
                            from db_async_wrapper import ImageAnalysisManager

                            async def save_to_db():
                                analysis_manager = ImageAnalysisManager()

                                # Enregistrer l'analyse (image_id=0 pour analyse batch)
                                await analysis_manager.save_analysis(
                                    image_type="streetview",
                                    image_id=0,
                                    analysis_type="yolo",
                                    model_name="yolov8n",
                                    results=results_data
                                )

                            asyncio.run(save_to_db())
                            logger.info("‚úÖ Analyse YOLO enregistr√©e en PostgreSQL")
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Impossible d'enregistrer en DB: {e}")
                        
                        st.session_state.yolo_results_path = str(results_file)
                        st.session_state.yolo_output_dir = output_dir
                        
                        st.success("‚úÖ Analyse YOLO termin√©e!")
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de l'analyse: {e}")
                        logger.error(f"Erreur YOLO: {e}", exc_info=True)
    
    # Afficher les r√©sultats si disponibles (charger depuis disque)
    if 'yolo_results_path' in st.session_state:
        try:
            with open(st.session_state.yolo_results_path, 'r', encoding='utf-8') as f:
                yolo_results = json.load(f)
            
            st.divider()
            display_yolo_results(yolo_results, st.session_state.yolo_output_dir)
            
            # Export JSON
            col1, col2 = st.columns([3, 1])
            with col2:
                json_str = json.dumps(yolo_results, indent=2, ensure_ascii=False)
                st.download_button(
                    label="üì• T√©l√©charger JSON",
                    data=json_str,
                    file_name=f"yolo_results_{address.replace(' ', '_')}.json",
                    mime="application/json"
                )
        except Exception as e:
            logger.error(f"Erreur chargement r√©sultats YOLO: {e}")
            st.error("‚ö†Ô∏è Impossible de charger les r√©sultats")
    
    st.divider()
    
    # === SECTION 2: ANALYSE DE CARTES ===
    st.subheader("üó∫Ô∏è Analyse de segmentation des cartes")
    
    # R√©cup√©rer les images satellites
    satellite_images = get_satellite_images(address)
    
    if not satellite_images:
        st.warning("‚ö†Ô∏è Aucune carte satellite disponible. T√©l√©chargez d'abord les cartes dans l'onglet 'üó∫Ô∏è Cartes & Images'.")
    else:
        # Trouver les paires satellite/roadmap
        satellite_imgs = [img for img in satellite_images if 'satellite' in img['name']]
        roadmap_imgs = [img for img in satellite_images if 'roadmap' in img['name']]
        
        if satellite_imgs and roadmap_imgs:
            st.success(f"‚úÖ {len(satellite_imgs)} paires de cartes disponibles")
            
            # S√©lection du zoom
            zoom_options = []
            for sat_img in satellite_imgs:
                # Extraire le zoom du nom (ex: map_z17_satellite.png)
                match = re.search(r'_z(\d+)_', sat_img['name'])
                if match:
                    zoom = int(match.group(1))
                    if zoom not in zoom_options:
                        zoom_options.append(zoom)
            
            if zoom_options:
                selected_zoom = st.selectbox("Niveau de zoom", sorted(zoom_options), index=0)
                
                # Trouver les images correspondantes
                sat_img = next((img for img in satellite_imgs if f'_z{selected_zoom}_' in img['name']), None)
                road_img = next((img for img in roadmap_imgs if f'_z{selected_zoom}_' in img['name']), None)
                
                if sat_img and road_img:
                    # Bouton de lancement
                    if st.button("üó∫Ô∏è Lancer l'analyse de cartes", type="primary"):
                        with st.spinner(f"üîç Analyse de segmentation en cours (zoom {selected_zoom})..."):
                            try:
                                results, output_dir = run_map_analysis(
                                    satellite_path=sat_img['path'],
                                    roadmap_path=road_img['path'],
                                    zoom=selected_zoom,
                                    address=address
                                )
                                # analyzer.save_results(str(output_dir)) est d√©j√† appel√© dans run_map_analysis
                                results_file = Path(output_dir) / f"statistics_z{selected_zoom}.json"
                                # Note: map_analyzer sauvegarde les stats dans statistics_z{zoom}.json
                                
                                # ‚úÖ Sauvegarder aussi en PostgreSQL
                                try:
                                    import asyncio
                                    from db_async_wrapper import ImageAnalysisManager

                                    async def save_to_db():
                                        analysis_manager = ImageAnalysisManager()

                                        # Enregistrer l'analyse (image_id=0 pour analyse batch)
                                        await analysis_manager.save_analysis(
                                            image_type="satellite",
                                            image_id=0,
                                            analysis_type="segmentation",
                                            model_name="deeplabv3",
                                            results=results
                                        )

                                    asyncio.run(save_to_db())
                                    logger.info("‚úÖ Analyse Map enregistr√©e en PostgreSQL")
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è Impossible d'enregistrer en DB: {e}")
                                
                                st.session_state.map_results_path = str(results_file)
                                st.session_state.map_output_dir = output_dir
                                
                                st.success("‚úÖ Analyse de cartes termin√©e!")
                                st.rerun()
                                
                            except Exception as e:
                                st.error(f"‚ùå Erreur lors de l'analyse: {e}")
                                logger.error(f"Erreur analyse cartes: {e}", exc_info=True)
        else:
            st.warning("‚ö†Ô∏è Paires satellite/roadmap incompl√®tes. Assurez-vous d'avoir t√©l√©charg√© les deux types de cartes.")
    
    # Afficher les r√©sultats si disponibles (charger depuis disque)
    if 'map_results_path' in st.session_state:
        try:
            with open(st.session_state.map_results_path, 'r', encoding='utf-8') as f:
                map_results = json.load(f)
            
            st.divider()
            display_map_analysis_results(map_results, st.session_state.map_output_dir)
            
            # Export JSON
            col1, col2 = st.columns([3, 1])
            with col2:
                json_str = json.dumps(map_results, indent=2, default=str, ensure_ascii=False)
                st.download_button(
                    label="üì• T√©l√©charger JSON",
                    data=json_str,
                    file_name=f"map_analysis_{address.replace(' ', '_')}.json",
                    mime="application/json"
                )
        except Exception as e:
            logger.error(f"Erreur chargement r√©sultats Map: {e}")
            st.error("‚ö†Ô∏è Impossible de charger les r√©sultats")
